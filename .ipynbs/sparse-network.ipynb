{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11516339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ed43e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from customLayer import CustomLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e433544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xor(x):\n",
    "    return reduce(lambda a, b: a ^ b, x)\n",
    "\n",
    "batch_size = 5000\n",
    "in_features = 10\n",
    "X = np.random.randint(0, 2, size=(batch_size, in_features))\n",
    "y = np.array([xor(x) for x in X])\n",
    "\n",
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cb5dcee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[:4000], y[:4000]\n",
    "X_val, y_val = X[4000:], y[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0f69771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_out_features = 15\n",
    "first_layer_out_features_allowed = 8\n",
    "second_layer_out_features = 20\n",
    "second_layer_out_features_allowed = 10\n",
    "\n",
    "class SimpleSparseModel(nn.Module):\n",
    "    def __init__(self, in_features = in_features, out_features = 2):\n",
    "        super().__init__()\n",
    "        self._layer1 = CustomLayer(in_features, \n",
    "                                        first_layer_out_features, \n",
    "                                        out_features_allowed=first_layer_out_features_allowed)\n",
    "        self._layer2 = CustomLayer(first_layer_out_features, \n",
    "                                        second_layer_out_features, \n",
    "                                        out_features_allowed=second_layer_out_features_allowed)\n",
    "        self._layer3 = CustomLayer(second_layer_out_features, out_features)\n",
    "        nn.Linear(in_features, out_features).forward\n",
    "\n",
    "    def forward(self, x, return_acts = False):\n",
    "        x_l1 = self._layer1(x)\n",
    "        x_l2 = self._layer2(x_l1)\n",
    "        out = self._layer3(x_l2)\n",
    "        if return_acts:\n",
    "            return out, {\"l1\": x_l1, \"l2\": x_l2, \"l3\": out}\n",
    "        return out\n",
    "    \n",
    "class SimpleDenseModel(nn.Module):\n",
    "    def __init__(self, in_features = in_features, out_features = 2):\n",
    "        super().__init__()\n",
    "        self._layer1 = CustomLayer(in_features, first_layer_out_features)\n",
    "        self._layer2 = CustomLayer(first_layer_out_features, second_layer_out_features)\n",
    "        self._layer3 = CustomLayer(second_layer_out_features, out_features)\n",
    "        nn.Linear(in_features, out_features).forward\n",
    "        self.net = nn.Sequential(\n",
    "            self._layer1,\n",
    "            self._layer2,\n",
    "            self._layer3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a49ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def orthogonality_loss(h):\n",
    "    \"\"\"\n",
    "    h: (batch_size, hidden_dim) activations\n",
    "    returns scalar regularization loss\n",
    "    \"\"\"\n",
    "    h_norm = F.normalize(h, p=2, dim=1)  # shape: (batch_size, hidden_dim)\n",
    "\n",
    "    G = torch.matmul(h_norm, h_norm.T)  # shape: (batch_size, batch_size)\n",
    "\n",
    "    I = torch.eye(G.size(0))\n",
    "    off_diag = G * (1 - I)\n",
    "\n",
    "    loss = (off_diag**2).mean()\n",
    "    return loss\n",
    "\n",
    "def train(model, X, y, criterion, optimizer, epochs=100, print_msg=False, ortho_lambda = None):\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        if ortho_lambda:\n",
    "            outputs, activations = model(X, return_acts = True)\n",
    "        else:\n",
    "            outputs = model(X)\n",
    "        \n",
    "        loss = criterion(outputs, y)\n",
    "        \n",
    "        if ortho_lambda:\n",
    "            ortho_loss = 0\n",
    "            ortho_loss += orthogonality_loss(activations[\"l3\"])\n",
    "            loss = loss + ortho_lambda * ortho_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if print_msg and (epoch+1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "def get_accuracy(model, X, y):\n",
    "    with torch.no_grad():\n",
    "        op = model(X)\n",
    "        accuracy = (torch.argmax(op, dim=1) == y).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "def train_and_evaluate(model, name = \"Model\", epochs=500, ortho_lambda = None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    train(model, X_train, y_train, criterion, optimizer, epochs=epochs, ortho_lambda=ortho_lambda)\n",
    "    print(f\"{name} Train Accuracy: {get_accuracy(model, X_train, y_train)*100:.4f}, Val Accuracy: {get_accuracy(model, X_val, y_val)*100:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "93853a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Accuracy: 89.0250, Val Accuracy: 90.6000\n"
     ]
    }
   ],
   "source": [
    "simpleSparseModel = SimpleSparseModel()\n",
    "train_and_evaluate(simpleSparseModel, epochs=200, ortho_lambda=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d8a8fefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train Accuracy: 94.7250, Val Accuracy: 94.4000\n"
     ]
    }
   ],
   "source": [
    "simpleSparseModel = SimpleSparseModel()\n",
    "train_and_evaluate(simpleSparseModel, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "a0ccef3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Model Train Accuracy: 85.7000, Val Accuracy: 86.3000\n",
      "Dense Model Train Accuracy: 91.4000, Val Accuracy: 89.3000\n",
      "Sparse Model Train Accuracy: 94.0500, Val Accuracy: 91.5000\n",
      "Dense Model Train Accuracy: 80.3000, Val Accuracy: 79.5000\n",
      "Sparse Model Train Accuracy: 93.3500, Val Accuracy: 92.9000\n",
      "Dense Model Train Accuracy: 92.3000, Val Accuracy: 89.2000\n",
      "Sparse Model Train Accuracy: 98.7250, Val Accuracy: 98.1000\n",
      "Dense Model Train Accuracy: 91.2750, Val Accuracy: 89.8000\n",
      "Sparse Model Train Accuracy: 95.9000, Val Accuracy: 94.9000\n",
      "Dense Model Train Accuracy: 95.1000, Val Accuracy: 94.6000\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    simpleSparseModel = SimpleSparseModel()\n",
    "    train_and_evaluate(simpleSparseModel, epochs=200, name=\"Sparse Model\")\n",
    "\n",
    "    simpleDenseModel = SimpleDenseModel()\n",
    "    train_and_evaluate(simpleDenseModel, epochs=200, name=\"Dense Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5be13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([0., 1., 0., 1., 0., 1., 1., 0., 0., 0.])\n",
      "True Output:  tensor(0)\n",
      "Model Output layer 1:  tensor([1.6230, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4005, 1.6835, 0.2312,\n",
      "        0.0000, 0.0000, 1.3362, 0.0000, 0.0000, 0.0000],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "Model Output layer 2:  tensor([0.0000, 2.5214, 0.0000, 0.0000, 2.7776, 2.7255, 3.2363, 0.0000, 0.0000,\n",
      "        2.2269], grad_fn=<SqueezeBackward1>)\n",
      "Model Output layer 3:  tensor([6.7198, 0.4847], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleSparseModel(\n",
       "  (_layer1): SparseCodedLayer(\n",
       "    (activation): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (_layer2): SparseCodedLayer(\n",
       "    (activation): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (_layer3): SparseCodedLayer(\n",
       "    (activation): LeakyReLU(negative_slope=0.1)\n",
       "  )\n",
       "  (net): Sequential(\n",
       "    (0): SparseCodedLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): SparseCodedLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (2): SparseCodedLayer(\n",
       "      (activation): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleSparseModel()\n",
    "train_and_evaluate(model)\n",
    "\n",
    "model.eval()\n",
    "random_input_index = 10\n",
    "random_input = X_val[random_input_index]\n",
    "random_output = y_val[random_input_index]\n",
    "# Add batch dimension\n",
    "input_batch = random_input.unsqueeze(0)\n",
    "model_layer_1_activations = model._layer1.forward(input_batch)\n",
    "model_layer_2_activations = model._layer2.forward(model_layer_1_activations)\n",
    "model_layer_3_activations = model._layer3.forward(model_layer_2_activations)\n",
    "print(\"Input: \", random_input)\n",
    "print(\"True Output: \", random_output)\n",
    "print(\"Model Output layer 1: \", model_layer_1_activations.squeeze(0))\n",
    "print(\"Model Output layer 2: \", model_layer_2_activations.squeeze(0))\n",
    "print(\"Model Output layer 3: \", model_layer_3_activations.squeeze(0))\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e669b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hippocampal-cortex-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
